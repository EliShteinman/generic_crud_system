# ××“×¨×™×š × ×›×•×Ÿ: PyMongo 4.0+ ××¡×™× ×›×¨×•× ×™ + MongoDB Atlas

## ×”×¢×¨×” ×—×©×•×‘×”!
**PyMongo 4.0+** ×›×•×œ×œ ×ª××™×›×” ××¡×™× ×›×¨×•× ×™×ª ××•×‘× ×™×ª! 
**Motor ×™×¦× ××©×™××•×©** - ××œ ×ª×©×ª××© ×‘×•!

---

## ×”×ª×§× ×” × ×›×•× ×”

```bash
# ×”×ª×§× ×” ×¢× ×ª××™×›×” ×‘-Atlas
pip install pymongo[srv] pandas asyncio

# ××œ ×ª×ª×§×™×Ÿ motor!
```

---

## ×—×™×‘×•×¨ ××¡×™× ×›×¨×•× ×™ × ×›×•×Ÿ ×œ-MongoDB Atlas

### 1. ×—×™×‘×•×¨ ××¡×™× ×›×¨×•× ×™ ×‘×¡×™×¡×™

```python
import asyncio
import pandas as pd
from pymongo import AsyncMongoClient
from pymongo.server_api import ServerApi
from typing import List, Dict, Any, Optional

class AsyncAtlasDAL:
    """DAL ××¡×™× ×›×¨×•× ×™ ×œ-MongoDB Atlas ×¢× PyMongo 4.0+"""
    
    def __init__(self, connection_string: str, database_name: str):
        self.connection_string = connection_string
        self.database_name = database_name
        self.client: Optional[AsyncMongoClient] = None
        self.db = None
        self.connected = False
    
    async def connect(self) -> bool:
        """×”×ª×—×‘×¨×•×ª ××¡×™× ×›×¨×•× ×™×ª ×œ-Atlas"""
        try:
            # PyMongo 4.0+ ×¢× ×ª××™×›×” ××¡×™× ×›×¨×•× ×™×ª ××•×‘× ×™×ª
            self.client = AsyncMongoClient(
                self.connection_string,
                server_api=ServerApi('1'),
                serverSelectionTimeoutMS=5000,
                connectTimeoutMS=5000,
                maxPoolSize=50,
                retryWrites=True
            )
            
            # ×‘×“×™×§×ª ×—×™×‘×•×¨ ××¡×™× ×›×¨×•× ×™×ª
            await self.client.admin.command('ping')
            print("âœ… ×—×™×‘×•×¨ ××¡×™× ×›×¨×•× ×™ ×œ-Atlas ×”×¦×œ×™×—!")
            
            self.db = self.client[self.database_name]
            self.connected = True
            return True
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×—×™×‘×•×¨ ××¡×™× ×›×¨×•× ×™: {e}")
            return False
    
    async def disconnect(self):
        """× ×™×ª×•×§ ××¡×™× ×›×¨×•× ×™"""
        if self.client:
            self.client.close()
            self.connected = False
            print("ğŸ”Œ × ×™×ª×•×§ ××¡×™× ×›×¨×•× ×™ ×”×•×©×œ×")
    
    def _ensure_connected(self):
        """×‘×“×™×§×” ×©×™×© ×—×™×‘×•×¨"""
        if not self.connected:
            raise RuntimeError("DAL ×œ× ××—×•×‘×¨ ×œ××¡×“ × ×ª×•× ×™×")
    
    async def find_documents(self, collection_name: str,
                           query: Dict[str, Any] = None,
                           projection: Dict[str, int] = None,
                           sort: List[tuple] = None,
                           limit: int = None,
                           skip: int = 0) -> List[Dict[str, Any]]:
        """××¦×™××ª ××¡××›×™× ××¡×™× ×›×¨×•× ×™×ª"""
        
        self._ensure_connected()
        collection = self.db[collection_name]
        
        # ×‘× ×™×™×ª cursor
        cursor = collection.find(query or {}, projection)
        
        if sort:
            cursor = cursor.sort(sort)
        if skip > 0:
            cursor = cursor.skip(skip)
        if limit:
            cursor = cursor.limit(limit)
        
        # ××™×˜×¨×¦×™×” ××¡×™× ×›×¨×•× ×™×ª ×¢×œ ×”cursor
        documents = []
        async for doc in cursor:
            if '_id' in doc:
                doc['_id'] = str(doc['_id'])
            documents.append(doc)
        
        return documents
    
    async def find_one_document(self, collection_name: str,
                              query: Dict[str, Any],
                              projection: Dict[str, int] = None) -> Optional[Dict[str, Any]]:
        """××¦×™××ª ××¡××š ××—×“ ××¡×™× ×›×¨×•× ×™×ª"""
        
        self._ensure_connected()
        collection = self.db[collection_name]
        
        doc = await collection.find_one(query, projection)
        if doc and '_id' in doc:
            doc['_id'] = str(doc['_id'])
        
        return doc
    
    async def count_documents(self, collection_name: str,
                            query: Dict[str, Any] = None) -> int:
        """×¡×¤×™×¨×ª ××¡××›×™× ××¡×™× ×›×¨×•× ×™×ª"""
        
        self._ensure_connected()
        collection = self.db[collection_name]
        
        return await collection.count_documents(query or {})
    
    async def aggregate_data(self, collection_name: str,
                           pipeline: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """××’×¨×’×¦×™×” ××¡×™× ×›×¨×•× ×™×ª"""
        
        self._ensure_connected()
        collection = self.db[collection_name]
        
        # cursor ××’×¨×’×¦×™×”
        cursor = collection.aggregate(pipeline)
        
        # ××™×˜×¨×¦×™×” ××¡×™× ×›×¨×•× ×™×ª
        results = []
        async for doc in cursor:
            if '_id' in doc and doc['_id'] is not None:
                doc['_id'] = str(doc['_id'])
            results.append(doc)
        
        return results
    
    async def get_distinct_values(self, collection_name: str,
                                field: str,
                                query: Dict[str, Any] = None) -> List[Any]:
        """×¢×¨×›×™× ×™×™×—×•×“×™×™× ××¡×™× ×›×¨×•× ×™"""
        
        self._ensure_connected()
        collection = self.db[collection_name]
        
        return await collection.distinct(field, query or {})

# ×“×•×’××” ×œ×©×™××•×©:
async def main():
    dal = AsyncAtlasDAL(
        "mongodb+srv://username:password@cluster.mongodb.net/?retryWrites=true&w=majority",
        "school_db"
    )
    
    if await dal.connect():
        # ×¢×‘×•×“×” ×¢× ×”× ×ª×•× ×™×...
        students = await dal.find_documents("students", {"active": True})
        print(f"× ××¦××• {len(students)} ×¡×˜×•×“× ×˜×™× ×¤×¢×™×œ×™×")
        
        await dal.disconnect()

# ×”×¨×¦×”
asyncio.run(main())
```

### 2. ×“×™×¤×“×•×£ ××¡×™× ×›×¨×•× ×™ × ×›×•×Ÿ (40 ××¡××›×™× ×‘×›×œ ×¤×¢×)

```python
async def paginate_async(dal: AsyncAtlasDAL, collection_name: str,
                        query: Dict = None, page_size: int = 40,
                        max_pages: int = None) -> List[Dict[str, Any]]:
    """×“×™×¤×“×•×£ ××¡×™× ×›×¨×•× ×™ ×¢×œ ××¡××›×™×"""
    
    # ×¡×¤×™×¨×” ×›×•×œ×œ×ª
    total_docs = await dal.count_documents(collection_name, query)
    total_pages = (total_docs + page_size - 1) // page_size
    
    if max_pages:
        total_pages = min(total_pages, max_pages)
    
    print(f"ğŸ“Š ×¡×”\"×› {total_docs} ××¡××›×™×, {total_pages} ×¢××•×“×™× ×©×œ {page_size}")
    
    all_data = []
    
    for page in range(total_pages):
        skip = page * page_size
        
        print(f"ğŸ“„ ×˜×•×¢×Ÿ ×¢××•×“ {page + 1}/{total_pages}...")
        
        # ×˜×¢×™× ×” ××¡×™× ×›×¨×•× ×™×ª ×©×œ ×”×¢××•×“
        page_data = await dal.find_documents(
            collection_name,
            query=query,
            skip=skip,
            limit=page_size
        )
        
        all_data.extend(page_data)
        print(f"   âœ… × ×˜×¢× ×• {len(page_data)} ××¡××›×™× (×¡×”\"×›: {len(all_data)})")
        
        # ×”×¤×¡×§×” ×§×˜× ×” (××•×¤×¦×™×•× ×œ×™)
        await asyncio.sleep(0.1)
    
    return all_data

# ×©×™××•×©:
async def load_all_students():
    dal = AsyncAtlasDAL("connection_string", "school_db")
    
    if await dal.connect():
        # ×˜×¢×™× ×” ×©×œ ×›×œ ×”×¡×˜×•×“× ×˜×™×, 40 ×‘×›×œ ×¤×¢×
        all_students = await paginate_async(
            dal, 
            "students",
            query={"active": True},
            page_size=40,
            max_pages=10  # ××§×¡×™××•× 10 ×¢××•×“×™× = 400 ×¡×˜×•×“× ×˜×™×
        )
        
        print(f"ğŸ“ × ×˜×¢× ×• ×¡×”\"×› {len(all_students)} ×¡×˜×•×“× ×˜×™×")
        await dal.disconnect()
        
        return all_students

# ×”×¨×¦×”
students = asyncio.run(load_all_students())
```

### 3. ×¢×™×‘×•×“ ××¡×™× ×›×¨×•× ×™ ×¢× Pandas

```python
async def async_mongo_to_pandas(dal: AsyncAtlasDAL, 
                               collection_name: str,
                               query: Dict = None,
                               max_documents: int = 10000) -> pd.DataFrame:
    """×”××¨×” ××¡×™× ×›×¨×•× ×™×ª ×©×œ MongoDB ×œ-Pandas"""
    
    print("ğŸ” ×‘×•×“×§ ×’×•×“×œ ××¢×¨×š ×”× ×ª×•× ×™×...")
    total_count = await dal.count_documents(collection_name, query)
    
    if total_count > max_documents:
        print(f"âš ï¸ ××¢×¨×š × ×ª×•× ×™× ×’×“×•×œ ({total_count:,} ××¡××›×™×)")
        print(f"   ×˜×•×¢×Ÿ ×¨×§ {max_documents:,} ×¨××©×•× ×™×...")
        
        documents = await dal.find_documents(
            collection_name,
            query=query,
            limit=max_documents
        )
    else:
        print(f"ğŸ“¦ ×˜×•×¢×Ÿ ×›×œ {total_count:,} ×”××¡××›×™×...")
        
        if total_count > 1000:
            # ×˜×¢×™× ×” ×‘×“×™×¤×“×•×£
            documents = await paginate_async(dal, collection_name, query, page_size=50)
        else:
            # ×˜×¢×™× ×” ×™×©×™×¨×”
            documents = await dal.find_documents(collection_name, query)
    
    if not documents:
        print("âš ï¸ ×œ× × ××¦××• × ×ª×•× ×™×")
        return pd.DataFrame()
    
    # ×”××¨×” ×œ-DataFrame
    df = pd.DataFrame(documents)
    
    # × ×™×§×•×™ ×‘×¡×™×¡×™
    df = df.dropna(how='all')
    
    # ×–×™×”×•×™ ××•×˜×•××˜×™ ×©×œ ×¢××•×“×•×ª ×ª××¨×™×š
    date_columns = []
    for col in df.columns:
        if any(keyword in col.lower() for keyword in ['date', 'time', 'created', 'updated']):
            try:
                df[col] = pd.to_datetime(df[col], errors='coerce')
                date_columns.append(col)
            except:
                pass
    
    if date_columns:
        print(f"ğŸ“… ×–×•×”×• ×¢××•×“×•×ª ×ª××¨×™×š: {date_columns}")
    
    print(f"ğŸ¼ DataFrame ××•×›×Ÿ: {len(df):,} ×©×•×¨×•×ª, {len(df.columns)} ×¢××•×“×•×ª")
    print(f"ğŸ“‹ ×¢××•×“×•×ª: {list(df.columns)}")
    
    return df

# ×©×™××•×©:
async def analyze_students():
    dal = AsyncAtlasDAL("connection_string", "school_db")
    
    if await dal.connect():
        # ×”××¨×” ×œ-DataFrame
        df = await async_mongo_to_pandas(
            dal, 
            "students",
            query={"active": True},
            max_documents=5000
        )
        
        await dal.disconnect()
        
        # ×¢×›×©×™×• × ×™×ª×•×— ×‘-Pandas
        if not df.empty:
            print("\nğŸ“Š × ×™×ª×•×— ×‘×¡×™×¡×™:")
            print(f"   ×××•×¦×¢ GPA: {df['gpa'].mean():.2f}")
            print(f"   ×”×ª×¤×œ×’×•×ª ×œ×¤×™ ×§×•×¨×¡:")
            print(df['course'].value_counts())
        
        return df

# ×”×¨×¦×”
df = asyncio.run(analyze_students())
```

### 4. ××’×¨×’×¦×™×” ××¡×™× ×›×¨×•× ×™×ª ××ª×§×“××ª

```python
async def advanced_aggregation_async(dal: AsyncAtlasDAL, 
                                   collection_name: str,
                                   analysis_type: str = "summary") -> pd.DataFrame:
    """××’×¨×’×¦×™×” ××ª×§×“××ª ××¡×™× ×›×¨×•× ×™×ª"""
    
    if analysis_type == "grade_analysis":
        pipeline = [
            # ×¡×™× ×•×Ÿ
            {"$match": {"active": True, "gpa": {"$exists": True}}},
            
            # ×§×™×‘×•×¥ ×œ×¤×™ ×§×•×¨×¡
            {"$group": {
                "_id": "$course",
                "student_count": {"$sum": 1},
                "avg_gpa": {"$avg": "$gpa"},
                "min_gpa": {"$min": "$gpa"},
                "max_gpa": {"$max": "$gpa"},
                "gpa_std": {"$stdDevPop": "$gpa"},
                "students": {"$push": {
                    "name": "$name",
                    "gpa": "$gpa",
                    "year": "$year"
                }}
            }},
            
            # ×”×•×¡×¤×ª ×—×™×©×•×‘×™×
            {"$addFields": {
                "gpa_range": {"$subtract": ["$max_gpa", "$min_gpa"]},
                "performance_category": {
                    "$switch": {
                        "branches": [
                            {"case": {"$gte": ["$avg_gpa", 3.5]}, "then": "××¦×•×™×Ÿ"},
                            {"case": {"$gte": ["$avg_gpa", 3.0]}, "then": "×˜×•×‘"},
                            {"case": {"$gte": ["$avg_gpa", 2.5]}, "then": "×‘×™× ×•× ×™"}
                        ],
                        "default": "× ××•×š"
                    }
                }
            }},
            
            # ××™×•×Ÿ
            {"$sort": {"avg_gpa": -1}}
        ]
        
        print("ğŸ”„ ××‘×¦×¢ ××’×¨×’×¦×™×” ××¡×™× ×›×¨×•× ×™×ª...")
        results = await dal.aggregate_data(collection_name, pipeline)
        
        # ×¢×™×‘×•×“ ×”×ª×•×¦××•×ª
        summary_data = []
        detailed_data = []
        
        for result in results:
            # × ×ª×•× ×™ ×¡×™×›×•×
            summary_data.append({
                'course': result['_id'],
                'student_count': result['student_count'],
                'avg_gpa': round(result['avg_gpa'], 2),
                'min_gpa': result['min_gpa'],
                'max_gpa': result['max_gpa'],
                'gpa_std': round(result.get('gpa_std', 0), 2),
                'gpa_range': round(result['gpa_range'], 2),
                'performance_category': result['performance_category']
            })
            
            # × ×ª×•× ×™× ××¤×•×¨×˜×™×
            for student in result.get('students', []):
                detailed_data.append({
                    'course': result['_id'],
                    'name': student['name'],
                    'gpa': student['gpa'],
                    'year': student.get('year', 'N/A'),
                    'course_avg': result['avg_gpa']
                })
        
        summary_df = pd.DataFrame(summary_data)
        detailed_df = pd.DataFrame(detailed_data)
        
        if not summary_df.empty:
            print("\nğŸ“Š ×ª×•×¦××•×ª ××’×¨×’×¦×™×”:")
            print("=" * 50)
            
            for _, course in summary_df.iterrows():
                print(f"ğŸ“š {course['course']}:")
                print(f"   ×¡×˜×•×“× ×˜×™×: {course['student_count']}")
                print(f"   ×××•×¦×¢ GPA: {course['avg_gpa']}")
                print(f"   ×˜×•×•×—: {course['min_gpa']} - {course['max_gpa']}")
                print(f"   ×§×˜×’×•×¨×™×”: {course['performance_category']}")
                print()
        
        return summary_df, detailed_df
    
    elif analysis_type == "time_series":
        # ×“×•×’××” ×œ× ×™×ª×•×— ×–×× ×™
        pipeline = [
            {"$match": {"enrollment_date": {"$exists": True}}},
            
            {"$addFields": {
                "enrollment_month": {
                    "$dateToString": {
                        "format": "%Y-%m",
                        "date": {"$dateFromString": {"dateString": "$enrollment_date"}}
                    }
                }
            }},
            
            {"$group": {
                "_id": "$enrollment_month",
                "new_students": {"$sum": 1},
                "avg_gpa": {"$avg": "$gpa"}
            }},
            
            {"$sort": {"_id": 1}}
        ]
        
        results = await dal.aggregate_data(collection_name, pipeline)
        df = pd.DataFrame(results)
        
        if not df.empty:
            df['month'] = pd.to_datetime(df['_id'])
            df = df.drop('_id', axis=1).set_index('month')
            
            # ×—×™×©×•×‘ ××’××•×ª
            df['enrollment_trend'] = df['new_students'].pct_change()
            df['enrollment_ma3'] = df['new_students'].rolling(window=3).mean()
            
            print("ğŸ“ˆ × ×™×ª×•×— ×–×× ×™ - ×¨×™×©×•× ×¡×˜×•×“× ×˜×™×:")
            print(f"   ×××•×¦×¢ ×¨×™×©×•××™× ×—×•×“×©×™×™×: {df['new_students'].mean():.1f}")
            print(f"   ×—×•×“×© ×©×™×: {df['new_students'].idxmax().strftime('%Y-%m')} ({df['new_students'].max()} ×¡×˜×•×“× ×˜×™×)")
            print(f"   ××’××ª ×¦××™×—×” ×××•×¦×¢×ª: {df['enrollment_trend'].mean()*100:.1f}%")
        
        return df

# ×©×™××•×©:
async def full_analysis():
    dal = AsyncAtlasDAL("connection_string", "school_db")
    
    if await dal.connect():
        # × ×™×ª×•×— ×¦×™×•× ×™×
        summary_df, detailed_df = await advanced_aggregation_async(
            dal, "students", "grade_analysis"
        )
        
        # × ×™×ª×•×— ×–×× ×™
        time_df = await advanced_aggregation_async(
            dal, "students", "time_series"
        )
        
        await dal.disconnect()
        
        return summary_df, detailed_df, time_df

# ×”×¨×¦×”
summary, detailed, time_series = asyncio.run(full_analysis())
```

---

## ×–×¨×™××ª ×¢×‘×•×“×” ××œ××” ×œ××‘×—×Ÿ

```python
class ExamWorkflow:
    """×–×¨×™××ª ×¢×‘×•×“×” ××œ××” ×œ××‘×—×Ÿ ×¢× PyMongo ××¡×™× ×›×¨×•× ×™"""
    
    def __init__(self, connection_string: str, database_name: str):
        self.dal = AsyncAtlasDAL(connection_string, database_name)
    
    async def start_exam_analysis(self, collection_name: str) -> pd.DataFrame:
        """×ª×”×œ×™×š ××œ× ×œ× ×™×ª×•×— ×‘××‘×—×Ÿ"""
        
        print("ğŸš€ ××ª×—×™×œ × ×™×ª×•×— ×œ××‘×—×Ÿ...")
        
        # ×©×œ×‘ 1: ×—×™×‘×•×¨
        if not await self.dal.connect():
            print("âŒ × ×›×©×œ ×‘×—×™×‘×•×¨!")
            return pd.DataFrame()
        
        try:
            # ×©×œ×‘ 2: ×‘×“×™×§×” ×¨××©×•× ×™×ª
            print("\nğŸ” ×‘×“×™×§×” ×¨××©×•× ×™×ª:")
            sample = await self.dal.find_one_document(collection_name, {})
            if sample:
                print(f"   ××‘× ×” ××¡××š: {list(sample.keys())}")
                
            total_docs = await self.dal.count_documents(collection_name)
            print(f"   ×¡×”\"×› ××¡××›×™×: {total_docs:,}")
            
            # ×©×œ×‘ 3: ×”×—×œ×˜×” ×¢×œ ××¡×˜×¨×˜×’×™×”
            if total_docs > 10000:
                print(f"\nğŸ“Š ××¢×¨×š × ×ª×•× ×™× ×’×“×•×œ - ××©×ª××© ×‘××’×¨×’×¦×™×”")
                df = await self._large_dataset_strategy(collection_name)
            else:
                print(f"\nğŸ“¦ ××¢×¨×š × ×ª×•× ×™× ×§×˜×Ÿ - ×˜×•×¢×Ÿ ×”×›×œ")
                df = await self._small_dataset_strategy(collection_name)
            
            # ×©×œ×‘ 4: × ×™×ª×•×— ××”×™×¨
            if not df.empty:
                print(f"\nğŸ“‹ × ×™×ª×•×— ××”×™×¨:")
                self._quick_analysis(df)
            
            return df
            
        finally:
            await self.dal.disconnect()
    
    async def _small_dataset_strategy(self, collection_name: str) -> pd.DataFrame:
        """××¡×˜×¨×˜×’×™×” ×œ××¢×¨×š × ×ª×•× ×™× ×§×˜×Ÿ"""
        
        documents = await self.dal.find_documents(collection_name)
        df = pd.DataFrame(documents)
        
        print(f"âœ… × ×˜×¢×Ÿ DataFrame ×¢× {len(df)} ×©×•×¨×•×ª")
        return df
    
    async def _large_dataset_strategy(self, collection_name: str) -> pd.DataFrame:
        """××¡×˜×¨×˜×’×™×” ×œ××¢×¨×š × ×ª×•× ×™× ×’×“×•×œ"""
        
        # ×ª×—×™×œ×” - ×¡×™×›×•× ×¢× ××’×¨×’×¦×™×”
        pipeline = [
            {"$sample": {"size": 5000}},  # ×“×’×™××” ××§×¨××™×ª
            {"$project": {"_id": 0}}      # ×‘×œ×™ ID
        ]
        
        sample_data = await self.dal.aggregate_data(collection_name, pipeline)
        df = pd.DataFrame(sample_data)
        
        print(f"âœ… × ×˜×¢× ×” ×“×’×™××” ×©×œ {len(df)} ×©×•×¨×•×ª")
        return df
    
    def _quick_analysis(self, df: pd.DataFrame):
        """× ×™×ª×•×— ××”×™×¨ ×©×œ DataFrame"""
        
        print(f"   ×’×•×“×œ: {df.shape[0]:,} ×©×•×¨×•×ª, {df.shape[1]} ×¢××•×“×•×ª")
        
        # ×–×™×”×•×™ ×¢××•×“×•×ª ××¡×¤×¨×™×•×ª
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        if numeric_cols:
            print(f"   ×¢××•×“×•×ª ××¡×¤×¨×™×•×ª: {numeric_cols}")
            for col in numeric_cols[:2]:  # ×¨×§ 2 ×”×¨××©×•× ×•×ª
                mean_val = df[col].mean()
                print(f"      {col}: ×××•×¦×¢ = {mean_val:.2f}")
        
        # ×–×™×”×•×™ ×¢××•×“×•×ª ×˜×§×¡×˜
        text_cols = df.select_dtypes(include=['object']).columns.tolist()
        if text_cols:
            print(f"   ×¢××•×“×•×ª ×˜×§×¡×˜: {text_cols}")
            for col in text_cols[:2]:  # ×¨×§ 2 ×”×¨××©×•× ×•×ª
                unique_count = df[col].nunique()
                print(f"      {col}: {unique_count} ×¢×¨×›×™× ×™×™×—×•×“×™×™×")

# ×©×™××•×© ×‘××‘×—×Ÿ:
async def exam_analysis():
    workflow = ExamWorkflow(
        "mongodb+srv://username:password@cluster.mongodb.net/",
        "exam_database"
    )
    
    df = await workflow.start_exam_analysis("exam_collection")
    
    # ×”××©×š ×¢× × ×™×ª×•×— ×‘-Pandas...
    if not df.empty:
        print("\nğŸ¼ × ×™×ª×•×— Pandas:")
        print(df.describe())
        
        # ×“×•×’××” ×œ×§×™×‘×•×¥
        if 'category' in df.columns:
            print(f"\n×”×ª×¤×œ×’×•×ª ×œ×¤×™ ×§×˜×’×•×¨×™×”:")
            print(df['category'].value_counts())
    
    return df

# ×”×¨×¦×”
df = asyncio.run(exam_analysis())
```

---

## ×¡×™×›×•× - ×”×§×•×“ ×”×—×©×•×‘ ×œ××‘×—×Ÿ

### âœ… ×ª×‘× ×™×ª ××™× ×™××œ×™×ª ×œ××‘×—×Ÿ:

```python
import asyncio
import pandas as pd
from pymongo import AsyncMongoClient

async def exam_quick_start():
    # ×—×™×‘×•×¨
    client = AsyncMongoClient("mongodb+srv://...")
    db = client["database_name"]
    collection = db["collection_name"]
    
    # ×‘×“×™×§×” ×¨××©×•× ×™×ª
    sample = await collection.find_one()
    print(f"××‘× ×”: {list(sample.keys())}")
    
    total = await collection.count_documents({})
    print(f"×¡×”\"×›: {total}")
    
    # ×˜×¢×™× ×” (40 ×‘×›×œ ×¤×¢×)
    if total > 1000:
        # ×“×™×¤×“×•×£
        all_docs = []
        for skip in range(0, min(total, 2000), 40):  # ××§×¡×™××•× 2000
            cursor = collection.find({}).skip(skip).limit(40)
            batch = []
            async for doc in cursor:
                doc['_id'] = str(doc['_id'])
                batch.append(doc)
            all_docs.extend(batch)
            print(f"×˜×¢×Ÿ {len(all_docs)} ××ª×•×š {total}")
    else:
        # ×”×›×œ
        all_docs = []
        async for doc in collection.find({}):
            doc['_id'] = str(doc['_id'])
            all_docs.append(doc)
    
    # Pandas
    df = pd.DataFrame(all_docs)
    print(f"DataFrame: {df.shape}")
    
    # × ×™×ª×•×§
    client.close()
    
    return df

# ×”×¨×¦×”
df = asyncio.run(exam_quick_start())
```

**×¢×›×©×™×• ×–×” × ×›×•×Ÿ! PyMongo 4.0+ ××¡×™× ×›×¨×•× ×™ ×‘×œ×‘×“, ×‘×œ×™ Motor!** ğŸ¯